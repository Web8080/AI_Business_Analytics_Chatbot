# Copy to .env and set values. Safe for local; replace SECRET_KEY and URLs for production.

# OpenAI (optional; leave empty to use Ollama)
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4-turbo-preview

# Ollama (no API key). Local: http://localhost:11434. Production: set to your Ollama server URL (e.g. http://ollama:11434 or your EC2/ECS URL).
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# API
API_HOST=0.0.0.0
API_PORT=8000
API_RELOAD=True
API_DEBUG=True

# Database
DATABASE_URL=sqlite:///./analytics.db

# Email (report distribution)
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USERNAME=your_email@gmail.com
SMTP_PASSWORD=your_app_password
SMTP_FROM_EMAIL=your_email@gmail.com

# Analytics
CONFIDENCE_THRESHOLD=0.7
MAX_FORECAST_PERIODS=12
OUTLIER_DETECTION_THRESHOLD=3.0

# File upload
MAX_UPLOAD_SIZE_MB=50
ALLOWED_FILE_TYPES=pdf,csv,xlsx

# Logging
LOG_LEVEL=INFO
LOG_FILE=logs/analytics.log

# Reports
REPORT_OUTPUT_DIR=reports/generated
REPORT_COMPANY_NAME=AI QueryLens

# Full-Stack + Production (AWS). Replace yourdomain.com with your real domain after deploy.
SECRET_KEY=8k2-mQ9xLp4vN7wR1sY6tU3bH0jF5cAeZ8dG2nKpW9xVmJ4r
DEBUG=0
ALLOWED_HOSTS=localhost,127.0.0.1,.yourdomain.com,.execute-api.us-east-1.amazonaws.com
CORS_ALLOWED_ORIGINS=http://localhost:3000,https://yourdomain.com,https://www.yourdomain.com
NODE_WS_PORT=3001
DJANGO_API_URL=http://localhost:8000
NEXT_PUBLIC_API_URL=http://localhost:8000
NEXT_PUBLIC_WS_URL=ws://localhost:3001

# Production override (when deploying to AWS): set SECRET_KEY to a new random 50-char string per environment.
# For Ollama in production, run Ollama on a server (e.g. EC2) and set:
#   OLLAMA_BASE_URL=http://your-ollama-host:11434
#   OLLAMA_MODEL=llama3.2
